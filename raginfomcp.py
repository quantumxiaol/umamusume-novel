"""
RAG MCP
python raginfomcp.py --http -p 7778
to activate the MCP server

"""
import io
import os
import sys
import uvicorn
import json
import argparse
import uvicorn

from langchain.prompts import PromptTemplate
from langchain.prompts import ChatPromptTemplate
from langchain_openai import OpenAI, ChatOpenAI
from typing import TypedDict, List
from langchain.text_splitter import RecursiveCharacterTextSplitter
from pydantic import BaseModel
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain_community.vectorstores import FAISS

from langchain_community.document_loaders import TextLoader,CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.prompts import ChatPromptTemplate
from starlette.middleware.cors import CORSMiddleware

from langchain.schema import Document
# from langchain.embeddings import HuggingFaceEmbeddings
# from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
from dotenv import load_dotenv
import argparse
import uvicorn
import contextlib
from mcp.server import FastMCP
from collections.abc import AsyncIterator
from mcp.server.fastmcp import FastMCP
from starlette.applications import Starlette
from mcp.server.sse import SseServerTransport
from starlette.requests import Request
from starlette.routing import Mount, Route
from starlette.types import Receive, Scope, Send
from mcp.server import Server
from mcp.server.streamable_http_manager import StreamableHTTPSessionManager

from dotenv import load_dotenv

from RAG import initialize_rag, rag_manager

load_dotenv(".env")

model_name=os.getenv("INFO_LLM_MODEL_NAME")
api_key=os.getenv("INFO_LLM_MODEL_API_KEY")
api_base=os.getenv("INFO_LLM_MODEL_BASE_URL")

ua=os.getenv("USER_AGENT")


# åˆå§‹åŒ– LLM æ¨¡åž‹
llm = ChatOpenAI(
    model_name=model_name,
    api_key=api_key,
    base_url=api_base,
)

# åˆå§‹åŒ–RAGç³»ç»Ÿ
print("æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
initialize_rag(mode="auto", force_rebuild=False)

# èŽ·å–æ£€ç´¢å™¨
retriever = rag_manager.vectorstore.as_retriever(search_kwargs={"k": 10})

# åˆ›å»ºå¸¦æœ‰ system æ¶ˆæ¯çš„æ¨¡æ¿
prompt_template = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªèµ›é©¬å¨˜ä¿¡æ¯æŸ¥è¯¢åŠ©æ‰‹ã€‚
               ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹è¿°ç»™å®šçš„å·²çŸ¥ä¿¡æ¯å›žç­”ç”¨æˆ·é—®é¢˜ã€‚
               ç¡®ä¿ä½ çš„å›žå¤å®Œå…¨ä¾æ®ä¸‹è¿°å·²çŸ¥ä¿¡æ¯ï¼Œä¸è¦ç¼–é€ ç­”æ¡ˆã€‚
               è¯·ç”¨ä¸­æ–‡å›žç­”ç”¨æˆ·é—®é¢˜ã€‚

               å·²çŸ¥ä¿¡æ¯:
               {context} """),
    ("user", "{question}")
])

# å®šä¹‰RetrievalQAé“¾
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt_template},
    retriever=retriever,
    return_source_documents=True
)


mcp = FastMCP("RAG Search MCP")


@mcp.tool(description="""
            Use Local Vector Database to answer questions about Umamusume characters.
            contain accurate and basic information about Umamusume characters.
            input: AnswerResponse
            Parameters:{question: str}
            output: AnswerResponse
            Example:{
                "question": "What is the birthday of Rice Shower?"
            }
            Result:{
                "answer": "Rice Shower was born on 3/05."
            }

""")

async def rag(question: str):
    try:
        # èŽ·å–ç”¨æˆ·é—®é¢˜
        user_question = question
        print(user_question)

        # é€šè¿‡RAGé“¾ç”Ÿæˆå›žç­”
        raw_answer = qa_chain.invoke(user_question)

        if isinstance(raw_answer, dict):
            answer_text = raw_answer.get("result", str(raw_answer))  # æå– result å­—æ®µ
        else:
            answer_text = raw_answer

        # è¿”å›žç­”æ¡ˆ
        print(answer_text)
        return {
            "status":"success",
            "result":str(answer_text)
        }
    except Exception as e:
        return {
            "status": "error",
            "message": str(e)
        }        

@mcp.tool(description="""
    æœç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚
    
    å‚æ•°:
        query (str): æœç´¢æŸ¥è¯¢
        k (int): è¿”å›žçš„æ–‡æ¡£æ•°é‡ï¼Œé»˜è®¤ä¸º3
    
    è¿”å›ž:
        dict: åŒ…å«æœç´¢ç»“æžœçš„å­—å…¸
""")
async def search_documents(query: str, k: int = 3):
    try:
        # ä½¿ç”¨RAGç®¡ç†å™¨è¿›è¡Œæœç´¢
        results = rag_manager.search(query, k=k)
        
        search_results = []
        for i, doc in enumerate(results, 1):
            search_results.append({
                "id": i,
                "content": doc.page_content,
                "source": doc.metadata.get("source", "Unknown"),
                "metadata": doc.metadata
            })
        
        return {
            "status": "success",
            "results": search_results
        }
    except Exception as e:
        return {
            "status": "error",
            "message": str(e)
        }

@mcp.tool(description="""
    é‡æ–°åŠ è½½RAGç³»ç»Ÿã€‚
    
    å‚æ•°:
        force_rebuild (bool): æ˜¯å¦å¼ºåˆ¶é‡å»ºå‘é‡æ•°æ®åº“ï¼Œé»˜è®¤ä¸ºTrue
    
    è¿”å›ž:
        dict: æ“ä½œç»“æžœ
""")
async def reload_rag(force_rebuild: bool = True):
    try:
        initialize_rag(mode="auto", force_rebuild=force_rebuild)
        
        # æ›´æ–°qa_chainçš„retriever
        global qa_chain, retriever
        retriever = rag_manager.vectorstore.as_retriever(search_kwargs={"k": 10})
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            chain_type_kwargs={"prompt": prompt_template},
            retriever=retriever,
            return_source_documents=True
        )
        
        return {
            "status": "success",
            "message": "RAGç³»ç»Ÿå·²é‡æ–°åŠ è½½"
        }
    except Exception as e:
        return {
            "status": "error",
            "message": str(e)
        }


def create_starlette_app(mcp_server: Server, *, debug: bool = False) -> Starlette:
    sse = SseServerTransport("/messages/")
    session_manager = StreamableHTTPSessionManager(
        app=mcp_server,
        event_store=None,
        json_response=True,
        stateless=True,
    )

    async def handle_sse(request: Request) -> None:
        async with sse.connect_sse(
            request.scope,
            request.receive,
            request._send,
        ) as (read_stream, write_stream):
            await mcp_server.run(
                read_stream,
                write_stream,
                mcp_server.create_initialization_options(),
            )

    async def handle_streamable_http(
        scope: Scope, receive: Receive, send: Send
    ) -> None:
        await session_manager.handle_request(scope, receive, send)

    @contextlib.asynccontextmanager
    async def lifespan(app: Starlette) -> AsyncIterator[None]:
        """Context manager for session manager."""
        async with session_manager.run():
            print("Application started with StreamableHTTP session manager!")
            try:
                yield
            finally:
                print("Application shutting down...")

    return Starlette(
        debug=debug,
        routes=[
            Route("/sse", endpoint=handle_sse),
            Mount("/mcp", app=handle_streamable_http),
            Mount("/messages/", app=sse.handle_post_message),
        ],
        lifespan=lifespan,
    )


# Main entry point
def main():
    mcp_server = mcp._mcp_server

    parser = argparse.ArgumentParser(description="Run Search and Crawl MCP server")

    parser.add_argument(
        "--http",
        action="store_true",
        help="Run the server with Streamable HTTP and SSE transport rather than STDIO (default: False)",
    )
    parser.add_argument(
        "--sse",
        action="store_true",
        help="(Deprecated) An alias for --http (default: False)",
    )
    parser.add_argument(
        "--host", default=None, help="Host to bind to (default: 127.0.0.1)"
    )
    parser.add_argument(
        "--port","-p", type=int, default=None, help="Port to listen on (default: 8887)"
    )
    args = parser.parse_args()
    print(f"ðŸš€ Starting server on port {args.port}")
    use_http = args.http or args.sse

    if not use_http and (args.host or args.port):
        parser.error(
            "Host and port arguments are only valid when using streamable HTTP or SSE transport (see: --http)."
        )
        sys.exit(1)

    if use_http:
        starlette_app = create_starlette_app(mcp_server, debug=True)
        uvicorn.run(
            starlette_app,
            host=args.host if args.host else "127.0.0.1",
            port=args.port if args.port else 7778,
        )
    else:
        mcp.run()


if __name__ == "__main__":
    main()